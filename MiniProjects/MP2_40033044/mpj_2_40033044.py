# -*- coding: utf-8 -*-
"""MPJ-2-40033044.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lzDMcW3Fow4Ym2RvLoCKBubAyhRliOmN

# Loading And Describtions
"""

# Import necessary libraries
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler # Import if not already done
from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2, RFE
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA
from sklearn.model_selection import StratifiedKFold, cross_validate # Import for CV

from sklearn.tree import DecisionTreeClassifier # The model we're using
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report


from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.datasets import load_breast_cancer
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2, RFE
from sklearn.datasets import load_breast_cancer
import pandas as pd
from scipy.stats import zscore
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.model_selection import cross_val_score

# Load the Breast Cancer Wisconsin dataset
data = load_breast_cancer()

# Convert to pandas DataFrame for easier exploration
df = pd.DataFrame(data.data, columns=data.feature_names)

# Add the target variable (labels)
df['target'] = data.target
# print(data.keys())
print(data.DESCR)

X_full = pd.DataFrame(data.data, columns=data.feature_names)
y_full = pd.Series(data.target, name='diagnosis')
print("Original Full Data Shape (X_full):", X_full.shape)
print("Original Full Target Shape (y_full):", y_full.shape)
print("-" * 50)

"""#  Preprocessing

##  Outlier detection (IQR & Z-score)
"""

iqr = df.quantile(0.75) - df.quantile(0.25)

print("IQR for each feature:")
print(iqr.round(2))

outlier_z = (np.abs(df.apply(zscore)) > 3).sum()

print("Outlier count (|Z| > 3) for each feature:")
print(outlier_z)

"""## Visualisation"""

plt.figure(figsize=(4 * 4, (df.shape[1] + 4 - 1) // 4 * 3)) # Adjust figure size for better readability
plt.suptitle('Box Plots of Breast Cancer Dataset Features', fontsize=16, y=1.02) # Overall title

# Iterate through each feature and create a box plot
# for i, feature in enumerate(df.columns):
#     plt.subplot(num_rows, num_cols, i + 1) # Create subplot for current feature
#     sns.boxplot(y=df[feature]) # Create box plot for the feature
#     plt.title(feature, fontsize=10) # Set title for the subplot (feature name)
#     plt.ylabel('') # Remove y-axis label to avoid clutter, as feature name is title
#     plt.tick_params(axis='y', labelsize=8) # Adjust y-axis tick label size

# plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjust layout to prevent titles from overlapping
# plt.show()

# You can also plot box plots grouped by diagnosis if you added the target column:
plt.figure(figsize=(4 * 4, (df.shape[1] + 4 - 1) // 4 * 3))
plt.suptitle('Box Plots of Breast Cancer Dataset Features by Diagnosis', fontsize=16, y=1.02)
for i, feature in enumerate(data.feature_names):
    plt.subplot((df.shape[1] + 4 - 1) // 4, 4, i + 1)
    sns.boxplot(x='target', y=feature, data=df)
    plt.title(feature, fontsize=10)
    plt.xlabel('')
    plt.ylabel('')
    plt.tick_params(axis='y', labelsize=8)
plt.tight_layout(rect=[0, 0.03, 1, 0.98])
plt.show()

"""## PCA and LDA"""

scaler = StandardScaler()
X_scaled_full = scaler.fit_transform(X_full)
X_scaled_full_df = pd.DataFrame(X_scaled_full, columns=X_full.columns)
lda_dr_full = LinearDiscriminantAnalysis(n_components=1)
X_lda_dr_full = lda_dr_full.fit_transform(X_scaled_full, y_full)
X_lda_dr_full = pd.DataFrame(X_lda_dr_full, columns=['LD1'])

pca_full = PCA(n_components=2) # Using 2 components for visualization, adjust as needed
X_pca_full = pca_full.fit_transform(X_scaled_full)
X_pca_full = pd.DataFrame(X_pca_full, columns=[f'PC{i+1}' for i in range(X_pca_full.shape[1])])

"""# Feature selection

## MI
"""

mi_scores_full = mutual_info_classif(X_full, y_full, random_state=42)
mi_series_full = pd.Series(mi_scores_full, index=X_full.columns).sort_values(ascending=False)
top_mi_features_full = mi_series_full.head(10).index.tolist()
X_mi_full = X_full[top_mi_features_full]


# Plot Mutual Information Scores
# plt.figure(figsize=(10, 6))
# plt.barh(X.columns, mi_scores)
# plt.xlabel('Mutual Information Score')
# plt.title('Mutual Information Scores for Each Feature')
# plt.show()

"""## RFE"""

estimator_rfe_full = LogisticRegression(max_iter=1000, random_state=42)
rfe_selector_full = RFE(estimator=estimator_rfe_full, n_features_to_select=10, step=1)
rfe_selector_full.fit(X_scaled_full_df, y_full)
rfe_support_full = rfe_selector_full.get_support()
top_rfe_features_full = X_full.columns[rfe_support_full].tolist()
X_rfe_full = X_scaled_full_df[top_rfe_features_full]

# plt.figure(figsize=(10, 6))
# plt.barh(X.columns, rfe_ranking)
# plt.xlabel('RFE Ranking')
# plt.title('RFE Feature Ranking')
# plt.show()

"""## Chi-square"""

selector_chi2_full = SelectKBest(score_func=chi2, k=10)
selector_chi2_full.fit(X_full, y_full)
selected_chi2_features_mask_full = selector_chi2_full.get_support()
top_chi2_features_full = X_full.columns[selected_chi2_features_mask_full].tolist()
X_chi2_full = X_full[top_chi2_features_full]
X_Kbest_full = X_chi2_full # Kbest with chi2 is the same

# Step 4: Visualize the top features
# plt.figure(figsize=(10, 6))
# plt.barh(selected_features, chi_scores[chi_selector.get_support()], color="skyblue")
# plt.xlabel('Chi-Square Score')
# plt.title('Top Features Selected by Chi-Square Test Debugged')
# plt.gca().invert_yaxis()  # Invert y-axis to show highest score at the top
# plt.show()

"""## Anova (k-best)"""

# selector = SelectKBest(score_func=chi2, k=10) # Using chi2 as score_func for consistency with above
# # You could also use score_func=f_classif for numerical features
# selector.fit(X, y) # Fit on original X

# # Get selected features
# selected_features_mask = selector.get_support()
# top_selectkbest_features = X.columns[selected_features_mask].tolist()
# # print("Top 10 features by SelectKBest (chi2 score_func):\n", top_selectkbest_features)
# print("Scores for Top 10 (from SelectKBest): \n",  pd.Series(selector.scores_, index=X.columns)[selected_features_mask].sort_values(ascending=False))
# X_test_Kbest = X_test[top_selectkbest_features]
# X_train_Kbest = X_train[top_selectkbest_features]

"""# Cross validation

"""

# --- Define the Cross-Validation Strategy ---
# 5-fold stratified cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scoring = ['accuracy', 'precision', 'recall', 'f1'] # Metrics to collect

"""# Clasification"""

feature_sets_full = {
    "Original": X_full,
    "Scaled": X_scaled_full_df,
    "MI": X_mi_full,
    "RFE": X_rfe_full,
    "Chi2": X_chi2_full,
    "KBest": X_Kbest_full,
    "PCA": X_pca_full,
    "LDA_DR": X_lda_dr_full,
}

classifiers = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Naive Bayes": GaussianNB(),
    "SVM": SVC(random_state=42),
    "LDA": LinearDiscriminantAnalysis(), # LDA used as a classifier
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Bagging": BaggingClassifier(random_state=42)
}


all_results = []


for model_name, model in classifiers.items():
    for feature_set_name, X_data_for_cv in feature_sets_full.items():

            # Perform cross-validation
            cv_results = cross_validate(model, X_data_for_cv, y_full, cv=cv, scoring=scoring, n_jobs=-1)

            # Calculate mean scores across all folds
            avg_accuracy = cv_results['test_accuracy'].mean()
            avg_precision = cv_results['test_precision'].mean()
            avg_recall = cv_results['test_recall'].mean()
            avg_f1 = cv_results['test_f1'].mean()

            # Store the average metrics in the results list
            all_results.append({
                'Model': model_name,
                'Feature Set': feature_set_name,
                'Accuracy': avg_accuracy,
                'Precision': avg_precision,
                'Recall': avg_recall,
                'F1-Score': avg_f1
            })

print("\n\n--- Comprehensive Model Performance Summary (Cross-Validation) ---")
results_df = pd.DataFrame(all_results)

# Sort the results: first by 'Recall' (descending), then by 'Accuracy' (descending)
sorted_results_df = results_df.sort_values(by=['Recall', 'Accuracy'], ascending=[False, False])

print(sorted_results_df.round(4))